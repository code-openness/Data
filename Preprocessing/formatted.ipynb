{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pik_edoc_20190404.csv loaded\n",
      "unescaped\n",
      "formatted\n",
      "data_formatted.csv saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"this scripts fixes the encoding of some non-UTF characters that are saved with the\n",
    "Numeric character reference (for example: รง was saved as &#231;)\n",
    "Thankfully, the html library can unescape these characters for so we can write the\n",
    "text back as UTF\n",
    "\"\"\"\n",
    "from html import unescape\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "inputFile = 'pik_edoc_20190404.csv'\n",
    "outputFile = 'data_formatted.csv'\n",
    "\n",
    "data = None\n",
    "with open(inputFile, 'r', encoding='UTF-8') as file:\n",
    "    data = file.read()\n",
    "    print(inputFile + ' loaded')\n",
    "\n",
    "# unescape to fix the encoding of some chars\n",
    "data = StringIO(unescape(data))\n",
    "print('unescaped')\n",
    "\n",
    "#read string as csv file\n",
    "df = pd.read_csv(data, encoding=\"utf8\", sep=',')\n",
    "\n",
    "#remove last column, its empty\n",
    "df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "#replace all \\N with NaN (pandas like it this way)\n",
    "df.replace(\"\\\\N\", np.nan, inplace=True)\n",
    "\n",
    "#some authors and editors names have a : at the end, remove that\n",
    "def RemoveColon(string):\n",
    "    return string.replace(':', '')\n",
    "\n",
    "df['authors'] = df['authors'].astype(str).apply(RemoveColon)\n",
    "df['editors'] = df['editors'].astype(str).apply(RemoveColon)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "as per Email from PIK:\n",
    "Das was unter \"keywords\" steht sind die\n",
    "alten Abteilungsnamen, die bis vor der Evaluation des Instituts in den 2000ern Bestand\n",
    "hatten. Danach wurden neue Domainnamen gebildet - die ab diesem Zeitpunkt im Feld x9\n",
    "hinterlegt sind. Tats?chliche Keywords liegen also, wenn vorhanden, in Feld \"x1\". \n",
    "however, the field x9 does not exist in the data we received\n",
    "\"\"\"\n",
    "df.rename(columns={\n",
    "'keywords': 'oldDepartmentNames',\n",
    "'x1 ( =Feld \"Keyword\";  u.a. belegt mit Info zu peer-review, wenn kein ISI-Journal)':'keywordsAndPeerReview',\n",
    "'x4 ( = DOI / Identifier)':'DOI',\n",
    "'relation (= Serie)': 'series'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"formatted\")\n",
    "df.to_csv(outputFile, encoding=\"utf8\", index=False)\n",
    "\n",
    "print(outputFile, \"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.read_csv('data_formatted.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that contain status 'submitted' in column 'year'\n",
    "df_copy = df_copy[~df_copy['year'].str.contains('submitted', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy[~df_copy['year'].str.contains('Submitted', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row that contains 'Marburg' in column 'year'\n",
    "df_copy=df_copy.drop([3238])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numbers of entries in 'year' except for 'submitted' entries\n",
    "df_years=df_copy\n",
    "year = []\n",
    "for _, row in df_years.iterrows():\n",
    "    _id = row['id']\n",
    "    names = str(row['year']).split(' ')\n",
    "    for name in names:\n",
    "        year.append([_id, name.strip()])\n",
    "year = pd.DataFrame(year, columns=['id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years=year[~year['year'].str.contains('[A-Z]', regex=True, flags= re.I)] #.to_csv(\"year\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of rows with NaN in column'year'\n",
    "df_nan=pd.read_csv('data_formatted.csv', sep=',')\n",
    "df_nan=df_temp2.loc[df_nan['year'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan= pd.DataFrame(df_nan, columns=['id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate table of NaN entries in column 'year' and table with numerical entry\n",
    "df_concat=pd.concat([df_years, df_nan], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tables on id, add cleaned 'year' data to complete table\n",
    "result = pd.merge(df_copy,\n",
    "                 df_concat[['id','year']],\n",
    "                 on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop obsolete 'year' column\n",
    "result=result.drop(columns=['year_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column\n",
    "result=result.rename(index=str, columns={\"year_y\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace values of '08/11/07' structure\n",
    "result.at['3506', 'year'] = 2007\n",
    "result.at['3508', 'year'] = 2007\n",
    "result.at['3509', 'year'] = 2007\n",
    "result.at['3511', 'year'] = 2007\n",
    "result.at['3512', 'year'] = 2007\n",
    "result.at['3514', 'year'] = 2007\n",
    "result.at['3583', 'year'] = 2007\n",
    "result.at['3600', 'year'] = 2007\n",
    "result.at['3604', 'year'] = 2008\n",
    "result.at['7861', 'year'] = 2017\n",
    "result.at['7862', 'year'] = 2017\n",
    "\n",
    "# replace wrong values \n",
    "result.at['7923', 'year'] = 2018\n",
    "result.at['5588', 'year'] = 2012\n",
    "result.at['8244', 'year'] = 2018\n",
    "\n",
    "# replace wrong value of '16'\n",
    "result.at['6874', 'year']= 2015\n",
    "\n",
    "# drop rows having '9.' as entry in column 'year'\n",
    "result=result.drop(index='7926')\n",
    "result=result.drop(index='7924')\n",
    "result=result.drop(index='7922')\n",
    "result=result.drop(index='7401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether 'id' is still unique\n",
    "#result.groupby('id').count().sort_values('id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_cleaned.csv saved\n"
     ]
    }
   ],
   "source": [
    "outputFile = 'year_cleaned.csv'\n",
    "result.to_csv(outputFile, encoding=\"utf8\", index=False)\n",
    "print(outputFile, \"saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
